894
ИЗУЧЕНИЕ МЕТОДОВ КЛАССИФИКАЦИИ ДОКУМЕНТОВ ДЛЯ ОПРЕДЕЛЕНИЯ ЭМОЦИОНАЛЬНОЙ ОКРАСКИ ТЕКСТА
3 Сравнение классификаторов 
----------
Тестирование и обучение классификаторов проводилось на одних и тех же данных.
Для визуализации результатов классификатора использовалась матрица ошибок. Матрица ошибок сводит в таблицу процент верных предсказаний для каждого класса, поэтому становится легче увидеть, какие классы наименее точно предсказаны для данного классификатора. В идеале классификатор должен получить почти 100% правильных предсказаний, поэтому все элементы вне побочной диагонали должны быть как можно ближе к нулю, как на рисунке 12.
Рисунок 12 – Пример матрицы ошибок
Начнем анализ с самого простого классификатора из рассматриваемых: классификатор на основе метода TextBlob. Классификатор показывает следующие результаты предсказания, изображенные с помощью матрицы ошибок на рисунке 13.
Рисунок 13 – Матрица ошибок предсказания TextBlob
На рисунке 14 покажем точность и F-меру полученных предсказаний.
Рисунок 14 – Оценка TextBlob
Метод, работающий на правилах и словарях, показал плохую точность, а также F-меру, что говорит о том, что классификатор не мог точно определять, к какому из 5 классов принадлежит рассматриваемое предложение. Из матрицы ошибок видно, что классификатор с трудом отделяет нейтральный класс от всех остальных. Это связано с тем, что классификатор на основе TextBlob пытается дать результат, основанный на прямом результате анализа грамматики: он не пытается проверить, является ли все предложение отрицательным или нет, а определяет тональность отдельных слов и после усредняет значение для определения тональности всего предложения. И в результате усреднения большинство предложений получили нейтральную окраску.
Рассмотрим классификатор, построенный на основе VADER, который так же работает на правилах. Классификатор показывает предсказания, изображенные на рисунке 15.
Рисунок 15 – Матрица ошибок предсказания VADER
На рисунке 16 покажем точность и F-меру классификатора.
Рисунок 16 – Оценка VADER
Классификатор на основе VADER так же, как и предыдущий классификатор, усредняет тональности всех слов в предложение, но VADER был разработан с акцентом на тексты в социальных сетях. Это означает, что в нем много внимания уделяется правилам, которые отражают суть текста, обычно встречаемого в социальных сетях: короткие предложения со смайликами, повторяющиеся слова и обильное использование знаков препинания. Этим и объясняется большой разброс вне побочной диагонали: очень низкие или очень высокие составные оценки присваиваются тексту, который имеет много капитализации, пунктуации, повторения слов и смайликов. Тем не менее классификатор на основе VADER показывает лучшие результаты, чем классификатор на основе TextBlob, что можно увидеть на рисунке 17.
Рисунок 17 – Сравнение предсказаний классификаторов
Недостатком методов, основанных на словарях и правилах, является большая затратность на составление этих самых словарей и правил, а также неспособность правильно обрабатывать незнакомые конструкции и слова, а в условиях постоянно развивающегося языка это большой минус.
От подходов, основанных на правилах и словарях, перейдем к машинному обучению с учителем. Рассмотрим классификатор на основе логической регрессии. Классификатор показывает предсказания, изображенные на рисунке 18.
Рисунок 18 – Матрица ошибок логической регрессии
На рисунке 19 покажем точность и F-меру классификатора.
Рисунок 19 – Оценка логической регрессии
Сравним результаты классификатора на основе логической регрессии с результатами предыдущих классификаторов на рисунке 20.
Рисунок 20 – Сравнение предсказаний классификаторов
Как видим, машинное обучение с учителем показывает себя гораздо лучше методов на словарях и правилах, однако в случае с логической регрессией результаты буду значительно лучше, если данные будут линейно разделяемы, а в случае с 5 классами добиться этого крайне сложно. Протестируем классификаторы на двухзначной шкале тональности, а именно отнесем предложения к отрицательному и положительному классам. На рисунке 21 покажем матрицу ошибок для классификатора на основе TextBlob.
Рисунок 21 – Матрица ошибок TextBlob
На рисунке 22 покажем матрицу ошибок для классификатора на основе VADER.
Рисунок 22 – Матрица ошибок VADER
На рисунке 23 покажем матрицу ошибок для классификатора на основе логичстиеской регрессии.
Рисунок 23 – Матрица ошибок логистической регрессии
И сравним результаты классификаторов на рисунке 24.
Рисунок 24 – Сравнение предсказаний классификаторов
Логическая регрессия смогла отнести к правильным классам 80 процентов входных предложений, что является крайне хорошим результатом в задаче определения тональности текста и по этому показателю она превосходит классификаторы на основе TextBlob и VADER.
Если же мы посмотрим на другой рассматриваемый метод машинного обучения с учителем – метод опорных векторов, то на рисунке 25 увидим превосходство логической регрессии в точности в задаче бинарной классификации.
Рисунок 25 – Сравнение предсказаний классификаторов
Но также на рисунке 26 увидим улучшение этого показателя у метода опорных векторов перед логической регрессией в задаче отнесения к 5 классам. Действительно SVM поддерживает как линейные, так и нелинейные решения, к тому же он лучше справляется с выбросами.
Рисунок 26 – Сравнение предсказаний классификаторов
На рисунке 27 отобразим матрицу ошибок для SVM.
Рисунок 27 – Матрица ошибок SVM
Процент правильно определенных нейтральных предложений все ещё низок, но в сравнении с предыдущими классификаторами SVM точнее относит предложения к крайне отрицательным и крайне положительным классам.
У классификатора, основанного на методе FastText, есть ряд преимуществ в сравнении с предыдущими рассматриваемыми. Иерархический метод классификации, обладающий большой информационной ёмкостью. Для модели векторных представлений слов используется skip-gram с негативным сэмплированием, таким образом для обучения векторной модели создаются отрицательные примеры, то есть показываются пары слов, которые не являются соседями по контексту. Но главным преимуществом выступает добавление к основной модели subword-модели – представления слова через цепочки символов (n-граммы) с n от 3 до 6 символов от начала до конца слова плюс само слово целиком.
Такой подход позволяет работать с теми словами, которые модель раннее не встречала. Совокупность этих преимуществ выливается в самую большую точность для задачи отнесения предложения к одному из пяти классов из рассматриваемых классификаторов, изображенную на рисунке 28.
Рисунок 28 – Сравнение предсказаний классификаторов
На матрице ошибок, изображенной на рисунке 29, видно, что классификатор гораздо точнее определяет предложения, имеющие нейтральную окраску, что и дает более высокую точность.
Рисунок 29 – Матрица ошибок FastText