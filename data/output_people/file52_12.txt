841
ПЕРСОНАЛЬНЫЙ АССИСТЕНТ С ГОЛОСОВЫМ УПРАВЛЕНИЕМ НА ОСНОВЕ МОБИЛЬНОГО УСТРОЙСТВА 
1. АНАЛИТИЧЕСКАЯ ЧАСТЬ 
1.2. Теоретические основы технологии распознавания речи 
1.2.2. Методы и алгоритмы распознавания речи 
----------
Методы и алгоритмы, которые использовались до сих пор, могут быть разделены на следующие большие классы:
1) Динамическое программирование — временные динамические алгоритмы (Dynamic Time Warping).
a) Контекстно-зависимая классификация. При еѐ реализации из потока речи выделяются отдельные лексические элементы — фонемы и аллофоны, которые затем объединяются в слоги и морфемы.
2)  Методы дискриминантного анализа, основанные на Байесовской дискриминации (Bayesian discrimination);
3)  Скрытые Марковские модели (Hidden Markov Model);
Скрытой Марковской моделью (СММ) называется модель, состоящая из N состояний, в каждом из которых некоторая система может принимать одно из M значений какого-либо параметра. Вероятности переходов между состояниями задается матрицей вероятностей A={aij}, где aij – вероятность перехода из i-го в j-е состояние. Вероятности выпадения каждого из M значений параметра в каждом из N состояний задается вектором B={bj(k)}, где bj(k) – вероятность выпадения k-го значения параметра в j-м состоянии. Вероятность наступления начального состояния задается вектором π={πi}, где πi – вероятность того, что в начальный момент система окажется в i-м состоянии.
Таким образом, скрытой Марковской моделью называется тройка λ={A,B,π}. Использование скрытых Марковских моделей для распознавания речи основано на двух приближениях:
1)  Речь может быть разбита на фрагменты, соответствующие состояниям в СММ, параметры речи в пределах каждого фрагмента считаются постоянными.
2)  Вероятность каждого фрагмента зависит только от текущего состояния системы и не зависит от предыдущих состояний.
Модель называется «скрытой», так как нас, как правило, не интересует конкретная последовательность состояний, в которой пребывает система. Мы либо подаем на вход системы последовательности типа O={o1,o2,…oi} - где каждое oi – значение параметра (одно из M), принимаемое в i-й момент времени, а на выходе ожидаем модель λ={A,B,π}с максимальной вероятностью генерирующую такую последовательность, - либо наоборот подаем на вход параметры модели и генерируем порождаемую ей последовательность. И в том и другом случае система выступает как ―черный ящик‖, в котором скрыты действительные состояния системы, а связанная с ней модель заслуживает названия скрытой.
Для осуществления распознавания на основе скрытых моделей Маркова необходимо построить кодовую книгу, содержащую множество эталонных наборов для характерных признаков речи (например, коэффициентов линейного предсказания, распределения энергии по частотам и т.д.). Для этого записываются эталонные речевые фрагменты, разбиваются на элементарные составляющие (отрезки речи, в течении которых можно считать параметры речевого сигнала постоянными) и для каждого из них вычисляются значения характерных признаков. Одной элементарной составляющей будет соответствовать один набор признаков из множества наборов признаков словаря. [4]
Фрагмент речи разбивается на отрезки, в течении которых параметры речи можно считать постоянными. Для каждого отрезка вычисляются характерные признаки и подбирается запись кодовой книги с наиболее подходящими характеристиками. Номера этих записей и образуют последовательность наблюдений O={o1,o2,…oi} для модели Маркова. Каждому слову словаря соответствует одна такая последовательность. Далее A – матрица вероятностей переходов из одного минимального отрезка речи (номера записи кодовой книги) в другой минимальный отрезок речи (номер записи кодовой книги). В – вероятности выпадения в каждом состоянии конкретного номера кодовой книги (рисунок 4).
Рисунок 4 - Кодовая книга
На этапе настройки моделей Маркова мы применяем алгоритм Баума- Уэлча для имеющегося словаря и сопоставления каждому из его слов матрицы A и B.
При распознавании мы разбиваем речь на отрезки, для каждого вычисляем набор номеров кодовой страницы и применяем алгоритм прямого или обратного хода для вычисления вероятности соответствия данного звукового фрагмента определенному слову словаря. Если вероятность превышает некоторое пороговое значение – слово считается  распознанным.
4) 	Нейронные сети (Neural networks).
Искусственная нейронная сеть — это математическая модель, а также устройства параллельных вычислений, представляющие собой систему соединѐнных и взаимодействующих между собой простых процессоров (искусственных нейронов). Как математическая модель искусственная нейронная сеть представляет собой частный случай методов распознавания образов или дискриминантного анализа. Пример нейросети изображен на рисунке 5.
Каждый процессор подобной сети имеет дело только с сигналами, которые он периодически получает, и сигналами, которые он периодически посылает другим процессорам. И тем не менее, будучи соединѐнными в достаточно большую сеть с управляемым взаимодействием, такие локально простые процессоры вместе способны выполнять довольно сложные задачи.
[5]
Понятие возникло при изучении процессов, протекающих в мозге при мышлении, и при попытке смоделировать эти процессы. Полученные модели называются искусственными нейронными сетями (ИНС).
Рисунок 5 - Схема простой нейросети, где зелѐным обозначены входные элементы, жѐлтым — выходной элемент
Нейронные сети не программируются в привычном смысле этого слова, они обучаются. Возможность обучения — одно из главных преимуществ нейронных сетей перед традиционными алгоритмами. Технически обучение заключается в нахождении коэффициентов связей между нейронами. В процессе обучения нейронная сеть способна выявлять сложные зависимости между входными данными и выходными, а также выполнять обобщение. Это значит, что, в случае успешного обучения, сеть сможет вернуть верный результат на основании данных, которые отсутствовали в обучающей выборке.
Решение задачи распознавания с помощью нейронных сетей обладает значительным преимуществом перед алгоритмами, основанными на вычислении метрик – вычислительные затраты не зависят от количества слов в словаре. При увеличении длины словаря увеличивается лишь размер обучающей выборки, то есть нейронной сети требуется затратить больше времени на процесс обучения, но трудоемкость процесса распознавания не изменяется. Такая особенность позволяет оперировать с достаточно большим количеством слов в словарях. Недостатком нейросетевого подхода является отсутствие возможности добавления новых слов в словарь после окончания процесса обучения. Для разрешения этой проблемы может быть применена теория адаптивного резонанса. Нейронные сети, построенные в рамках теории адаптивного резонанса сохраняют пластичность при запоминании новых образов, и, в то же время, предотвращают модификацию старой
памяти. [6]