411
РАЗРАБОТКА ПРОГРАММЫ ДЛЯ ПОИСКА СОТРУДНИКОВ НА САЙТАХ ВАКАНСИЙ
2. Стек технологий для разработки и внедрения автоматизированного поиска резюме на различных работных сайтах по заданным параметрам 
2.1 Технологии Web Scrapping 
----------
Web Scrapping – это сбор данных с сайта и последующее преобразование их в необходимый формат. С развитием технологий появилась масса интернет ресурсов, которые несут в себе полезную информацию. Можно полагаться на какой-либо ресурс и пользоваться предоставляемыми им данными, а можно анализировать несколько ресурсов и получать больше качественной информации. Поиск резюме – это отличный пример для использования веб скраппинга, ведь вся работа сводится к следующему:
1)  Ввод необходимых данных для поиска.
2)  Автоматический поиск и сбор данных с сайтов.
3)  Анализ данных и последующая их обработка (вывод либо действие).
Для того, чтобы разобраться со «Скраппингом», необходимо знать следующие понятия:
1)  GET запрос – это обычный HTTP или HTTP/s запрос на URL ссылку с «Открытыми» параметрами, то есть все параметры (если они есть) запроса передаются в самой ссылке. Такие запросы используются для получения данных, которые может увидеть любой пользователь, и которые не обязательно скрывать.
2)  POST запрос – это HTTP или HTTP/s запрос на URL ссылку с «Закрытыми» параметрами, то есть все параметры запроса передаются в теле запроса в скрытом виде.  Такие запросы используются для авторизации на сайте, осуществления каких-либо действий на сайте, которые требуют дополнительных параметров. Например, «Поиск» требует наличия ключевых слов, так же на некоторых сайтах неавторизированным пользователям поиск запрещен, авторизация проверяется исходя из заголовка и тела нашего запроса. «Отправка комментария» требует нескольких параметров, зачастую это наличие авторизации, текст комментария, заголовок, время и так далее. Пожалуй, самый важный пример использования POST запроса – это авторизация. Существует огромное количество сайтов, на которых для того, чтобы получить доступ ко многим данным необходимо авторизоваться, и процесс веб скраппинга без авторизации становится невозможным.
3)  «Парсинг» - это уже анализ и обработка полученных с помощью GET или POST данных. Зачастую это строка с HTML кодом, в котором необходимо получить только определенную часть. Используя инструменты языка программирования можно осуществить быстрый и качественный сбор информации.
Сам Web Scrapping может быть реализован практически на любом языке программирования, разница будет лишь в реализации ключевых методов. Типовой вариант функциональной схемы работы скреппера приведен на рис.1.
Рисунок.1 Функциональная схема работы скреппера
Через запросы получают данные с сайта с указанным URL. Далее проверяется есть ли среди обработчиков «Обработчик 1» … «Обработчик N» тот, который настроен под конкретный сайт. Если да, то используется он, иначе используется «Главный обработчик». Если по какой-либо причине «главному обработчику» не удаётся распознать данные, используется «Вспомогательный обработчик», который уже настраивается персонально, например администратором. На выходе получаем готовые данные, которые можем отобразить либо использовать их для дальнейших действий, таких как сохранение в Таблицу, или отправка ответа на почту и так далее.