1202
ИНТЕЛЛЕКТУАЛЬНЫЙ АНАЛИЗ ПОТОКОВЫХ ДАННЫХ В БЕСПРОВОДНЫХ СЕНСОРНЫХ СЕТЯХ С ПОМОЩЬЮ ДЕРЕВЬЕВ РЕШЕНИЙ
4. Реализация и тестирование алгоритмов 
4.2. Тестирование и оценка результатов 
----------
Предположим, что нас интересует, какую зарплату в среднем получает человек в определенном возрасте, проживающий в определенном городе. Для этого необходимо узнать несколько параметров, таких как:
-город проживания;
- возраст;
-пол;
-образование;
-накопления за год;
-траты в месяц;
-семейное положения;
-сколько дней длится отпуск;
Зная, эти факторы попробуем составит дерево принятия решений. Подготовим данные, стандартом является формат ARFF, фактически это CSV с некоторыми методанными. Далее добавляем поля методанных в начало файла. На отдельных строчках добавляется следующая информация:
- название зависимости @relation имя;
- описание атрибутов @attribute: имя, тип;
- @data перед началом самих данных.
Различают следующие типы данных:
- численные (numeric,real,integer),
-перечислимые(nominal) ,
-строковые (string),
-дата (date[date format]),
-составной тип (relation).
Полученный файл необходимо поместить в систему  с помощью Open File вкладки Preprocess. Теперь мы можем редактировать файл уже в системе, изменения могут осуществляться как вручную, так и наложением на данные фильтра для их очищения или трансформации.
Фильтры делятся на два типа:
1.  применение, которых может вызвать отклонение (фактически эти фильтры требуют уже наличия каких-то знаний, полученных от примененного какого-то алгоритма обучения);
2.  которые можно применять к еще необработанными данными.
Далее в ходе работы будем использовать фильтры unsupervised.
RemoveType, Remove – для удаления определенных атрибутов, в том числе и по типу – необходимо, так как не все типы могут быть использованы в различных алгоритмах;
Disctretize – для перевода числового атрибута в перечислимый;
RemoveUseless – для удаления атрибута, значение которого варьируется слишком сильно;
ReplaceMissing Values – для замещения отсутствующих значений средними по атрибуту;
На данной вкладке можно выбрать зависимую переменную и увидеть в графическом виде ее зависимость от текущего выбранного атрибута. При помощи Visualize All представить зависимость этой переменной от всех атрибутов в графическом виде.
Для лучшего понимания работы программы рассмотрим небольшой пример.
1.  Описание данных, создание файла с расширением arff:
@relation 'Data'
@attribute city {Moscow,Belgorod,Krasnodar,Ivanovo,Lipetsk,Kaluga,Kazan,Vladimir,Rostov-on-Don,Voronezh,Bryansk}
@attribute age numeric
@attribute sex {Male,Female}
@attribute education {higher,average,heigher-not-full,school,school-9}
@attribute accumulation numeric
@attribute expenditure-month numeric
@attribute marital-status {Married-civ-spouse,Divorced,Never-married,Separated,Widowed,Married-spouse-absent,Married-AF-spouse}
@attribute holiday numeric
@attribute worked {yes,no}
@attribute income{<=25,25<50,>50}
@data
Belgorod,18,Male,school,12,5,Never-married,30,?,<=25
Moscow,25,Female,higher,50,23,Never-married,15,yes,>50
Krasnodar,45,Male,higher,126,45,Married-AF-spouse,14,no,>50
Voronezh,43,Female,average,100,20,Married-AF-spouse,43,yes,<=25
Bryansk,20,Male,average,10,20,Never-married,14,no,<=25
Rostov-on-Don,36,Male,higher,50,36,Married-AF-spouse,20,yes,25<50
Ivanovo,32,Female,higher,150,20,Widowed,14,no,25<50
2.  Загрузка файла в программу Weka:
Рисунок 4 -  Пример использование программы Weka
3.  Для выполнения классификации переходим на вкладку Classify. Там мы увидим окно Test Options. Выбираем Use Training Set, чтобы использовать модель, которую WEKA создаст на основе наших данных из *.arff – файла. Далее необходимо выбрать метод классификации:
Рисунок 5 - Вкладка Тest opinion
4.  Жмем кнопку старт и получаем результат:
=== Run information ===
Scheme:       weka.classifiers.trees.J48 -C 0.25 -M 2
Relation:     Data
Instances:    7
Attributes:   10
city
age
sex
education
accumulation
expenditure-month
marital-status
holiday
worked
income
Test mode:    evaluate on training data
=== Classifier model (full training set) ===
J48 pruned tree
------------------
education = higher: 25<50 (4.0/2.0)
education = average: <=25 (2.0)
education = heigher-not-full: <=25 (0.0)
education = school: <=25 (1.0)
education = school-9: <=25 (0.0)
Number of Leaves  : 	5
Size of the tree : 	6
Time taken to build model: 0.03 seconds
=== Evaluation on training set ===
Time taken to test model on training data: 0.01 seconds
=== Summary ===
Correctly Classified Instances           5               71.4286 %
Incorrectly Classified Instances         2               28.5714 %
Kappa statistic                          0.5625
Mean absolute error                      0.1905
Root mean squared error                  0.3086
Relative absolute error                 43.4783 %
Root relative squared error             66.0819 %
Total Number of Instances                7
=== Detailed Accuracy By Class ===
TP Rate  FP Rate  Precision  Recall   F-Measure  MCC   ROC Area  PRC Area  Class
1,000    0,000       1,000      1,000    1,000        1,000    1,000         1,000      <=25
1,000    0,400       0,500      1,000    0,667         0,548   0,800         0,500     25<50
0,000    0,000       0,000      0,000    0,000         0,000   0,800         0,500         >50
Weighted Avg.    0,714    0,114    0,571      0,714    0,619      0,585    0,886     0,714
=== Confusion Matrix ===
a b c   <-- classified as
3 0 0 | a = <=25
0 2 0 | b = 25<50
0 2 0 | c = >50
Из полученного результата можно увидеть, что:
* в блоке Classifier model строится дерево с указанием количества его уровня;
* в блоке Confusion Matrix строится матрица ответов на поставленный вопрос;
* в блоке Summary описывается время исполнения программы, вероятность неточного ответа.
Реализуем алгоритм С4.5 на выборке из 100,200,300,400,500 опрошенных людях, на основе этого составим сравнительную таблицу работы алгоритма.
Таблица 1 - Характеристика работы алгоритма C4.5 на данных о количестве заработной платы
Количество опрошенных
Точность классификации,%
Средняя ошибка метода,%
Средняя абсолютная ошибка
Средне-
квадратичная ошибка
Относительная абсолютная
Ошибка, %
Относительная квадратичная ошибка, %
Время выполнения моднли, сек
100
60
40
0.3101
0.4519
71.4321
96.9976
0.02
200
81.5
18.5
0.1451
0.3308
33.4364
71.0219
<0.01
(0.009)
300
93.7
6.3
0.0649
0.2066
15.081
44.5302
0.02
400
93.25
6.75
0.0672
0.2088
15.6573
45.0861
0.022
500
93.014
6.986
0.0642
0.2093
14.8704
45.0503
0.02
Реализуем алгоритм VFDT на выборке из 100,200,300,400,500 опрошенных людях, на основе этого составим сравнительную таблицу работы алгоритма.
Таблица 2 - Характеристика работы алгоритма VFDT на данных о количестве заработной платы
Количество опрошенных
Точность классификации,%
Средняя ошибка метода,%
Средняя абсолютная ошибка
Средне-
квадратичная ошибка
Относительная абсолютная
Ошибка, %
Относительная квадратичная ошибка, %
Время выполнения моднли, сек
100
80
20
0.2383
0.4089
52.5804
84.3023
<0.01
(0.003)
200
82
18
0.2307
0.3743
52.714
79.9834
<0.01
(0.004)
300
95.6667
4.333
0.044
0.1706
10.2212
36.7743
<0.01
(0.0033)
400
96
4
0.0382
0.1627
8.9065
35.1221
<0.01
(0.0037)
500
96.32
3.68
0.0341
0.1568
7.902
33.7487
<0.01
(0.005)
Для того, чтобы проанализировать и сравнить результаты работ алгоритмов составим графики.
Рисунок 6 - График времени работы алгоритмов C4.5 и VFDT
Рисунок 7 - График точности классификации алгоритмов C4.5 и VFDT
Из рисунков 5 и 6 можно сделать вывод, что коэффициент точности у алгоритмов растет с увеличением получаемой информации, причем коэффициенты близки к равным. А вот время работы алгоритмов значительно различается с приростом информации, алгоритм С4.5 значительно поднимается в верх, а вот VFDT изменяется незначительно.
Для более точного анализа, рассмотрим еще одну статистику, для частоты эксперимента возьмем такую же выборку из 100,200,300,400,500 опрошенных людей.
Узнаем, какова вероятность одобрения заявки на кредит, для этого необходимо уточнить несколько параметров, таких как:
-город проживания;
- возраст;
-пол;
-кредитная история;
-стабилен ли доход;
-траты в месяц;
-семейное положения;
-история работы;
После обоработки информации алгоритмами, получим данные о работе программы:
Таблица 3 - Характеристика работы алгоритма C4.5 на данных о кредитовании
Количество опрошенных
Точность классификации,%
Средняя ошибка метода,%
Средняя абсолютная ошибка
Средне-
квадратичная ошибка
Относит-я абсолютн. ошибка, %
Относит. квадратичная ошибка,%
Время выполн-я модели, сек
100
64
36
0.3037
0.4538
68.5996
96.4417
0.01
200
85
15
0.1515
0.2753
34.4275
58.6792
0.01
300
86.6667
13.33
0.1356
0.2604
30.8819
55.5748
0.02
400
86
14
0.135
0.2598
30.727
55.4344
0.027
500
85.4
14.6
0.1444
0.2687
32.8844
57.347
0.03
Таблица 4 - Характеристика работы алгоритма VFDT на данных о кредитовании
Количество опрошенных
Точность классификации,%
Средняя ошибка метода,%
Средняя абсолютная ошибка
Средне-
квадратичная ошибка
Относит-я абсолютн. ошибка, %
Относит. квадратичная ошибка,%
Время выполн-я модели, сек
100
65
35
0.3218
0.3461
65.9655
90.646
<0.01
(0.003)
200
76
24
0.2724
0.3562
61.5379
75.723
<0.01
(0.0035)
300
94
6
0.0649
0.2066
15.081
44.5302
<0.01
(0.005)
400
97.2
2.8
0.0341
0.1568
7.902
33.7487
<0.01
(0.0053)
500
97.7
2.3
0.034
0.156
7.9
33.7480
<0.01
(0.0072)
Для более наглядного анализа построим графики времени работы алгоритмов и их точности.
Рисунок 8 - График времени работы алгоритмов C4.5 и VFDT для данных о кредитовании
Рисунок 9 - График точности классификации алгоритмов C4.5 и VFDT для данных о кредитовании
Из рисунков 8 и 9 получили идентичные значения, что и в предыдущем примере.