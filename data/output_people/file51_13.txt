490
ИССЛЕДОВАНИЯ АЛГОРИТМОВ КОЛЛАБОРАТИВНОЙ ФИЛЬТРАЦИИ И РАЗРАБОТКА РАСШИРЯЕМОЙ РЕКОМЕНДАТЕЛЬНОЙ СИСТЕМЫ
3 Практическая реализация рекомендательной системы с неявной обратной связью через матричную факторизацию 
----------
Перед написанием кода для рекомендательной системы, обговорим некоторые моменты, а именно как работает ALS метод и почему именно он был реализован как единственным метод из аналогичных методов в библиотеке Spark. Прежде уже говорилось, что для коллаборативной фильтрации не требуется какой-либо информации о пользователях или предметах. Следовательно, может задаться вопрос как пользователи и элементы связаны друг с другом?
Оказывается, можно найти связь между пользователями и предметами, если использовать факторизацию матрицы. Часто, факторизация матрицы применяется в области сокращения размерности, где необходимо сократить количество исходных данных, сохранив при этом необходимую информацию.
Это можно сделать через сингулярное разложение матрицы(SVD).
По сути, можно взять большую матрицу взаимодействия пользователей с предметами и выявить латентные (или скрытые) особенности, которые позволят разложить эту матрицу на две другие матрицы, которые на порядок меньше, и в которых находятся латентные вектора пользователей и предметов соответственно. Это именно то, что ALS пытается сделать через факторизацию матрицы.
Рассмотрим рисунок 3, который расположен ниже, предположим, имеется  оригинальная матрица оценок RM×N, где M-количество пользователей и Nколичество предметов. Эта матрица является довольно разряженной, поскольку большинство пользователей взаимодействуют только с несколькими элементами. Можно разложить эту матрицу через произведение двух других матриц более низкого порядка: одна с размерами M×K, которая будет хранить латентные вектора признаков для всех наших пользователей (U), а вторая с размерами K×N, в которой будут находится латентные вектора признаков для каждого предмета (V). Перемножив эти две матрицы получим матрицу, которая будет равна исходной матрице R. Теперь получились две матрицы, которые являются плотными, и в которых хранятся латентные вектора признаков для каждого из предметов и пользователей.
Рисунок 3 – Факторизация матрицы
На рисунке 3 изображено разложение матрицы на произведение двух других более мелких матриц. Для того, чтобы найти значения матрицы U и V, можно либо использовать SVD (что потребует инвертирование потенциально очень большие матрицы, а это будет слишком дорого стоить в вычислительном отношении) для более точного решения задачи факторизации, или применить алгоритм ALS и получить приближенное решение. В случае с ALS, так как и множество пользователей U и множество предметов V являются независимыми, то есть надо найти решение лишь для одного вектора признаков в один момент времени, что означает, что он может быть запущен параллельно! (В этом просматривается большое преимущество и, возможно, именно поэтому этот метод был выбран для библиотеки Spark). Чтобы использовать метод ALS, можно случайным образом инициализировать U и найти подходящее решение для V. Затем нужно вернуться и найти решение для U, используя решение для
V. Эти действия выполняются до тех пор, пока мы не получим приближение к матрице R, которое будет наилучшим.
После того как были получены подходящие матрицы U и V, для того чтобы предсказать оценку пользователя u к объекту i можно просто взять скалярное произведение u-ой строки матрицы U и i-ого столбца матрицы V, и что дает рейтинг пользователя u к этому предмету i, даже если ранее пользователь u не взаимодействовал с предметом i. Эта базовая методология была принята для рекомендательных систем с неявной обратной связью в статье «Collaborative Filtering for Implicit Feedback Datasets». Далее рассмотрим эту методологию на конкретном примере.