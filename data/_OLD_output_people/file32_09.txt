530
КЛАССИФИКАЦИЯ МУЗЫКАЛЬНЫХ КОМПОЗИЦИЙ ПО ИСПОЛНИТЕЛЯМ НА ОСНОВЕ МАШИННОГО ОБУЧЕНИЯ 
2 Реализация алгоритма классификации. Описание используемых методов, функций и библиотек 
2.2 Извлечение информации из музыки 
----------
Каждый звуковой сигнал имеет множество характеристик, из которых следует отобрать нужные. Процесс получения информации для анализа называется извлечением объектов или извлечением сущностей (feature extraction). Такими характеристиками сигнала могут быть:
* частота пересечения нуля (zero crossing rate) – это частота изменения знака сигнала, т. е. частота, с которой сигнал меняется с положительного на отрицательный и обратно. Например, пусть есть некоторый сигнал и для него построен график амплитудной огибающей (рисунок 5) [11]
Рисунок 5 – График амплитудной огибающей сигнала
На графике видно 6 пересечений нуля. С помощью функции zero_crossing библиотеки librosa проверим, так ли это. Код и результат представлены на рисунке 6:
Рисунок 6 – Фрагмент программы, вычисляющей количество пересечений нуля амплитудной огибающей
Шесть переходов через нуль – всё верно. Функция zero_crossing_rate широко используется как для распознавания речи, так и для извлечения музыкальной информации. Для металла и рока этот параметр обычно выше, чем для других жанров, из-за большого количества ударных;
* спектральный центроид – указывает, где расположен «центр масс» звука и рассчитывается как средневзвешенное значение всех частот. В блюзовых композициях частоты равномерно распределены, и центроид лежит где-то в середине спектра. В металле же наблюдается выраженное смещение частот к концу композиции, поэтому и спектроид лежит ближе к концу спектра, как показано на рисунке 7:
Рисунок 7 – График спектрального центроида
* мел-частотные кепстральные коэффициенты (MFCC) сигнала – небольшой набор характеристик (обычно около 10-20) которые сжато описывают общую форму спектральной огибающей. В основном этот параметр моделирует характеристики человеческого голоса. [10]
Далее с помощью функции пакета librosa – features.mfcc – рассчитываются мел-частотные кепстральные коэффициенты. В файле hmm_trainer на основе полученных параметров и характеристик строится скрытая марковская модель. Параметр n_components — определяет число скрытых состояний. Опираясь на исследования в области обучения с помощью СММ, было установлено, что относительно неплохие модели можно строить, используя 6-8 скрытых состояний, а для получения более сложных моделей можно использовать больше, около 20 состояний, но тогда и время обучения увеличится во много раз. Остальные параметры отвечают за сходимость EM-алгоритма, ограничивая число итераций, точность и определяя тип ковариационных параметров состояний. ЕМ-алгоритм, который также называют алгоритмом Баумы-Велша, используется для нахождения неизвестных параметров скрытой марковской модели. Он использует алгоритм прямого и обратного хода. Именно он и занимается обучением модели в файле trainholder.
Так как hmmlearn используется для обучения без учителя, то процесс обучения строится следующим образом: для каждого класса обучается своя модель, далее тестовый сигнал прогоняется через каждую модель, где по нему рассчитывается логарифмическая вероятность score каждой модели. В итоге класс, которому соответствует модель, выдавшая наибольшую вероятность, и является владельцем этого тестового сигнала. Реализация показана на рисунке 8:
Рисунок 8 – Фрагмент реализации обучения модели
В общем случае, наш алгоритм классификации работает так: в папке с названием исполнителя для каждой из имеющихся в ней песен, то есть «.wav» файла, считаются MFCC, значения которых добавляются в матрицу признаков (np.array([])), причём строка соответствует фрейму, столбец соответствует номеру коэффициента из MFCC. После заполнения матрицы создается скрытая марковская модель для этого класса (исполнителя), и признаки передаются в EM-алгоритм для обучения. Далее осуществляется классификация: обращаемся к каждой модели и считаем для неё логарифмическую вероятность. Получаем сортированный по вероятностям набор классов, первый элемент которого показывает, кто является наиболее вероятным исполнителем данной песни.
Результат записывается в файл result.txt в программном файле test_predict.py, в котором осуществляется классификация песен из предварительно созданной папки «…/Tests».