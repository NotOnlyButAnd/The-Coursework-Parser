Evaluation Warning: The document was created with Spire.Doc for Python.
МИНИСТЕРСТВО ОБРАЗОВАНИЯ И НАУКИ РОССИЙСКОЙ ФЕДЕРАЦИИ
Федеральное государственное бюджетное образовательное учреждение
высшего образования
 «КУБАНСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ»
(ФГБОУ ВО «КубГУ»)

Кафедра вычислительных технологий












КУРСОВАЯ РАБОТА

 ПРИМЕНЕНИЕ МЕТОДОВ ИНТЕЛЛЕКТУАЛЬНОГО АНАЛИЗА ДЛЯ ПРЕДСКАЗАНИЯ РЕЗУЛЬТАТОВ СПОРТИВНЫХ СОРЕВНОВАНИЙ




Работу выполнил 							       М.И. Ващанов
		          (подпись, дата)		        (инициалы, фамилия)
Факультет компьютерных технологий и прикладной математики 3 курс
Направление 02.03.02 – «Фундаментальная информатика и информационные технологии» 
Научный руководитель 
доц., к.т.н.,                                               		      	              Т.А. Приходько
		(подпись, дата)			       (инициалы, фамилия)
Нормоконтролер 
ст.преп., к.т.н., 				     		  	             Е.Е. Полупанова
		(подпись, дата)			      (инициалы, фамилия)





Краснодар 2017
СОДЕРЖАНИЕ

ВВЕДЕНИЕ	2
1 Система сбора и хранения информации	3
1.1	Постановка задачи для системы сбора информации	3
1.2	Поиск матчей и сбор статистики.	4
1.3	Промежуточное хранение данных	5
1.4	Система хранения информации	6
1.5	Реализация непрерывной работы системы сбора информации	7
2 Система анализа данных	8
2.1 Инструменты анализа данных	8
2.2 Визуальный анализ данных	10
2.3 Постановка задачи на прогнозирование результата матча	12
2.4 Формальная постановка задачи классификации	13
2.5 Общие сведения о градиентном бустинге на решающих деревьях	13
2.6 Подбор гиперпараметров и обучение модели	15
2.7 Оценка качества модели с помощью кросс-валидации	17
3 Анализ полученных результатов	18
3.1 Анализ системы в разрезе точности критериев оценки результатов матча	18
3.2 Анализ системы в разрезе уверенности модели в своей классификации	19
ЗАКЛЮЧЕНИЕ	21
СПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ	22
ПРИЛОЖЕНИЕ	23









ВВЕДЕНИЕ
В настоящее время можно наблюдать бурное развитие систем и технологий сбора, хранения и обработки информации. Также расширяется и количество данных, которые используются в современных системах. В связи с этим стало возможным исследование и предсказание в режиме реального времени результата спортивных соревнований. В курсовой работе рассматриваются задачи сбора данных обо всех футбольных матчах, которые идут в момент работы системы, хранения и обновления этих данных, а также задачи анализа и предсказания результатов конкретного матча.
На данный момент существуют методы анализа статистики футбольного матча, которые доказали свою эффективность на практике, однако информации, какими способами были найдены эти методы в открытом доступе нет. 
Целью работы является построение системы, предсказывающей результат футбольного матча по первым 15 минутам игры.
Курсовая работа состоит из двух частей.
Первая часть работы содержит описание работы систем сбора и хранения информации. В ней рассматриваются вопросы создания системы сбора данных из сети Интернет в режиме реального времени, отслеживание каждого футбольного матча, обнаруженного системой, до его завершения, а также  вопросы способа хранения информации о матче.
Вторая часть данной работы посвящена интеллектуальному анализу данных. В неё входят построение предсказательных моделей, проверка их на корректность, выводы.

1 Система сбора и хранения информации
1.1  Постановка задачи для системы сбора информации
Система сбора информации должна решать следующие три задачи. Первой задачей является поиск футбольных матчей, удовлетворяющих критерию времени, прошедшего с начала матча. Второй задачей является непосредственно сбор статистики о футбольном матче. Третьей задачей является промежуточное хранение данных до завершения матча. 
1.2  Поиск матчей и сбор статистики.
Для решения задач поиска матчей и сбора статистики используется сайт betsapi.com. Для работы с сайтом используется библиотека для синтаксического разбора файлов HTML/XML beautiful soup 4. На сайте информация представляется в виде таблицы матчей. На рисунке 1 изображена таблица футбольных матчей с указанием времени с момента начала матча.

Рисунок 1 – Пример таблицы футбольных матчей
Для всех матчей, которые идут 10-20 минут, запоминается статистика игры. На рисунке 2 показан пример таблицы со статистикой для конкретного матча.

Рисунок 2 – Пример таблицы со статистикой матча
1.3  Промежуточное хранение данных
Для промежуточного хранения данных было рассмотрено 3 варианта организации системы хранения.
Первым вариантом было сохранение в базу данных статистики с последующим дописыванием туда количества голов в первом тайме и во всей игре. Достоинством данной схемы является относительно простая реализация. Недостатком является то, что в количество обращений к базе данных будет в три раза больше, чем при других вариантах. Такая система будет плохо масштабируема в будущем.
Два других варианта основываются на идее о том, что сначала нужно собрать все данные матча, а потом записывать их все сразу в базу данных.
Вторым вариантом является сохранение всей информации в оперативную память. Преимуществами такого решения является очень высокая скорость, практически отсутствие затрат на запись и считывание данных, простая реализация. Минусом является потеря данных при сбое системы.
Третьим вариантом является сохранение информации в NoSQL хранилище Redis. Данный вариант является компромиссным между первым и вторым вариантами. Так как в этом хранилище можно настроить произвольный таймер на запись данных в ПЗУ, то нагрузка на ПЗУ будет относительно невелика, а риск, что при сбое данные потеряются будет также сравнительно мал при достаточно маленьком значении таймера. Несмотря на кажущуюся привлекательность данного метода, он довольно сложен в реализации, и чтобы его использовать, необходимо ответить на некоторые другие вопросы. Например, что будет, если система даст сбой и не все данные будут записаны на диск? Каким образом обрабатывать вновь запущенной системе вариант, когда в хранилище уже есть какие-то данные, о которых текущей системе неизвестно? Даже если система знает, как обрабатывать данные, то возможен вариант, когда на сайте, с которого считывались данные, больше не существует страницы с тем матчем, статистика которого была записана. Это может произойти, например, при достаточно продолжительном отключении системы.
Ответы на эти вопросы выходят за рамки данной работы, поэтому для решения задачи промежуточного хранения данных был выбран вариант с хранением статистики в оперативной памяти.
1.4  Система хранения информации
В качестве долговременного хранилища статистики была выбрана СУБД SQLite 3. Данная СУБД широко распространена, является простой в использовании. Одним из существенных минусов этой СУБД является то, что для доступа к ней используются файловые дескрипторы операционной системы. Поэтому она не предназначена для систем с очень высокой нагрузкой. Однако, для того, чтобы она стала непригодной, необходимо, чтобы количество запросов в секунду к ней достигало 1000 и более. Реализуемая система и близко не подбирается к этим параметрам, так как сложно представить, что в мире больше одной тысячи футбольных матчей начинаются одновременно. Следовательно, использование SQLite 3 в качестве основной базы данных полностью оправдано.
1.5  Реализация непрерывной работы системы сбора информации
Так как система работает постоянно, необходимо продумать механизмы планирования задач и распределения нагрузки. Эти механизмы реализованы в библиотеке Celery [1]. Celery – это распределенная асинхронная очередь заданий, которая обладает широким функционалом. Celery умеет:
* выполнять задания асинхронно или синхронно
* выполнять периодические задания
* выполнять отложенные задания
* распределенное выполнение 
* в пределах одного worker'а возможно конкурентное выполнение нескольких задач (одновременно)
* выполнять задание повторно, если вылез exception
* ограничивать количество заданий в единицу времени
* routing заданий 
* несложно мониторить выполнение заданий
* выполнять подзадания
* присылать отчеты об exception'ах на email
В очереди может быть 4 разных задания. Все задания периодические. Все задания запущены одни и тем же процессом, т.к. необходимо, чтобы они использовали совместные ресурсы (так как выбрана модель сохранения промежуточных данных в оперативную память). Задания выполняются асинхронно.
 Первое задание отвечает за обновление  текущих матчей и сбор статистики о матче в промежутке 10-20 минут с начала матча. Статистика записывается в переменную типа словарь, где ключом является id матча. Оно запускается каждые 10 минут. 
Второе и третье задания отвечают за добавление к статистике матча количества голов, забитых командами за первый тайм и за всю игру соответственно. Эти задания выполняются 1 раз в 10 минут. 
Четвёртое задание отвечает за обновление переменных, которые используются 2 и 3 заданиями. Оно просматривает все матчи, и как только оно определяет, что закончился первый/второй тайм, то она добавляет соответствующий матч для просмотра 2/3 заданием. Это задание выполняется 1 раз в 5 минут.
2 Система анализа данных
	2.1 Инструменты анализа данных
Одним из наиболее популярных языков программирования для анализа данных является Python. Для него создано большое количество библиотек и фреймворков. В работе используется интерактивная оболочка IPython Jupyter Notebook. Данная оболочка поддерживает встроенный режим работы с самой популярной библиотекой визуализации для Python matplotlib. Также в ней присутствует функция разбиения исходного кода на независимые блоки, вследствие чего появляется возможность запуска программы “по частям”. Это является очень полезной функцией, потому что можно, например, один раз обучить некоторую модель в одном блоке кода, а анализ и тестирование её вывести в другие блоки, которые можно изменять, перезапускать, вручную менять последовательность их исполнения. Этот функционал получилось реализовать, потому что Python является интерпретируемым языком (т.е. исполняется построчно). 
Для визуализации в работе используются библиотеки matplotlib и seaborn. 
Хранение данных осуществляется в оперативной памяти с помощью библиотеки pandas. Pandas — программная библиотека на языке Python для обработки и анализа данных. Работа pandas с данными строится поверх библиотеки NumPy, являющейся инструментом более низкого уровня. Pandas предоставляет специальные структуры данных и операции для манипулирования числовыми таблицами и временными рядами. Название библиотеки происходит от эконометрического термина «панельные данные», используемого для описания многомерных структурированных наборов информации. Основные возможности библиотеки:
– 	объект DataFrame для манипулирования индексированными массивами двумерных данных;
– 	инструменты для обмена данными между структурами в памяти и файлами различных форматов;
– 	встроенные средства совмещения данных и способы обработки отсутствующей информации;
– 	переформатирование наборов данных, в том числе создание сводных таблиц;
– 	срез данных по значениям индекса, расширенные возможности индексирования, выборка из больших наборов данных;
– 	вставка и удаление столбцов данных;
– 	возможности группировки позволяют выполнять трёхэтапные операции типа «разделение, изменение, объединение»;
– 	слияние и объединение наборов данных;
– 	иерархическое индексирование позволяет работать с данными высокой размерности в структурах меньшей размерности;
–	работа с временными рядами: формирование временных периодов и изменение интервалов и т. д.
Также в работе используется библиотека для градиентного бустинга на деревьях eXtreme Gradient Boosting. С её помощью можно решать задачи классификации и регрессии. Также у неё есть инструменты для определения информативных признаков[2,3]. 
2.2 Визуальный анализ данных
Прежде чем работать с данными, необходимо как можно глубже понять их природу. Для этого часто используется визуальный анализ. Визуализация производится с помощью библиотеки seaborn. 
На рисунке 3 приведена тепловая карта для матрицы корреляций всех пар признаков. Оранжевыми точками обозначены матчи с количеством голов домашней команды большим 0. Синими точками обозначены матчи, в которых домашняя команда ни разу не забила. По диагонали расположены распределения признаков.

Рисунок 3 – Тепловая карта для матрицы корреляции признаков
Анализируя эту тепловую карту, можно сделать несколько наблюдений:
Признаки количества атак и опасных атак имеют сильную корреляцию. Это обусловлено тем, что много матчей начинается в одно и то же время (может идти в среднем до 15 матчей одновременно), а просмотреть все матчи сразу нельзя. На обработку одного матча уходит около 20 секунд. Следовательно, матчи, которые просмотрены последними, идут существенно больше времени, чем матчи, просмотренные в самом начале. 
Ожидаемо высокие коэффициенты корреляции между количеством ударов в створ ворот у второй команды и количеством забитых ей мячей, между владением мячом и количеством атак и опасных атак у обеих команд. В целом собранная выборка очень хорошо описывает связь параметров между собой. Все существенные корреляции имеют логическое обоснование.
Ещё одним информативным видом графиков является график boxplot. На рисунке 4 изображён этот тип графиков. Синяя часть показывает распределение значений каждого признака для каждого из результирующих классов.


Рисунок 4 – Графики boxplot
Из показанных графиков видно, что если домашняя команда забивает голы, то в среднем она уже на 15 минуте больше владеет мячом. Также хорошо заметно, что если у команды гостей много угловых на 15 минуте игры, то по статистике вряд ли домашняя команда забьёт хотя бы один гол.
2.3 Постановка задачи на прогнозирование результата матча
Вероятнее всего, бессмысленно ставить задачу точного предсказания счёта всего матча, зная статистику только первых 15 минут игры. Поэтому необходимо выбрать такой критерий, который, с одной стороны, как можно более точно описывал результат матча, а с другой стороны был бы истинным с наибольшей долей вероятности. Рассмотрим два критерия.
Первый критерий будет предсказывать количество голов, забитых командой, находящейся дома. Второй критерий будет предсказывать вероятность того, что первая команда забьёт хотя бы один гол. Очевидно, что первый критерий более информативен, однако интуитивно легче предсказать второй критерий.
В качестве задачи прогнозирования могут выступать задачи регрессии и классификации на исходном наборе данных. Рассмотрим особенности разных подходов к прогнозированию. 
Для прогнозирования второго критерия самым очевидным выбором является решение задачи обычной бинарной классификации. Для прогнозирования первого критерия можно использовать как классификацию, так и регрессию. Может показаться, что для предсказания этого критерия лучше подойдёт решение задачи регрессии, так как множество количества голов является числовым упорядоченным множеством. Но с другой стороны в результате решения будет получено вещественное число, которое надо как-то интерпретировать (желательнее всего получить степень вероятности того, что результатом будет целое число либо меньшее этого результата, либо большее результата). Из-за сложности задачи интерпретации гораздо легче представить целевой признак в виде классов для задачи классификации и решать именно эту задачу, так как в этой задаче обычно не сложно вывести вероятности попадания предсказываемого объекта к каждому из классов.
Таким образом, для предсказания обоих критериев было решено использовать решение задачи классификации.
2.4 Формальная постановка задачи классификации
Пусть X – множество описаний объектов, Y – конечное множество меток классов. Существует неизвестная целевая зависимость — отображение , значения которой известны только на объектах конечной обучающей выборки  Требуется построить алгоритм , способный классифицировать произвольный объект .
Существуют и различные виды задачи: 
1) Двухклассовая классификация. Наиболее простой в техническом отношении случай, который служит основой для решения более сложных задач.
          2) Многоклассовая классификация. Когда число классов достигает многих тысяч (например, при распознавании иероглифов или слитной речи), задача классификации становится существенно более трудной. Задача многоклассовой классификации может быть сведена к последовательности задач двухклассовой классификации[4, 5].
2.5 Общие сведения о градиентном бустинге на решающих деревьях
Решающие деревья воспроизводят логические схемы, позволяющие получить окончательное решение о классификации объекта с помощью ответов на иерархически организованную систему вопросов. Причём вопрос, задаваемый на последующем иерархическом уровне, зависит от ответа, полученного на предыдущем уровне. Дерево является простой моделью,  склонно к переобучению. Из-за этого на практике используются ансамбли деревьев. 
Существует две широко используемые стратегии обучения деревьев: решающий лес и градиентный бустинг. Решающий лес обучается по следующему алгоритму:
a.  случайно выбирается некоторое количество признаков и объектов;
b.  происходит обучение одного дерева на выборке из пункта a;
c.  пока количество деревьев не станет равным N, выполняются пункты a-b. N - гиперпараметр алгоритма, отвечающий за конечное количество деревьев в лесу.
Градиентный бустинг работает по другому принципу. Следующее дерево строится с помощью предыдущей модели так, чтобы увеличить точность предсказания. Такая стратегия иначе называется аддитивным обучением: 

t – количество этапов обучения (или количество деревьев),– предсказанное  значение,  – i-ое решающее дерево. Целевая функция имеет вид:

 – функция ошибки,   – параметр регуляризации. Функция ошибки обязательно должна быть дифференцируемой, так как при обучении модели решается задача оптимизации функции l методом градиентного спуска[3]. 
2.6 Подбор гиперпараметров и обучение модели 
Гиперпараметры – настройки алгоритма, решающего задачу. В случае с градиентным бустингом на решающих деревьях гиперпараметрами являются:
* максимальная глубина одного дерева;
* коэффициент регуляризации;
* количество деревьев в модели;
* шаг обучения (learning rate);
* минимальный порог разбиения выборки;
* целевая функция и другие.
Наиболее простой способ подбора гиперпараметров – перебор по заданной сетке. Этот подход называется GridSearch. Достоинства метода в том, что если задать плотную сетку, то можно получить хорошую модель на выходе. Очевидным минусом является большой объём вычислений. Существует много вариаций поиска по сетке без полного перебора. Можно, например, использовать подход случайного выбора параметров сетки или  стохастического градиентного спуска[6]. Однако стоит отметить, что для цели курсовой работы подойдёт и обычный поиск по сетке, так как выборка не очень большая и, следовательно, вычислительных ресурсов для обучения модели хватает даже у ноутбука. 
	На рисунке 5 показан процесс задания сетки перебора параметров,  поиска оптимальных параметров с помощью инструмента GridSearchCV и результат этого поиска.

Рисунок 5 – поиск оптимальных значений гиперпараметров


	На рисунке 6 показано обучение модели, нахождение вероятностей принадлежности для всех объектов из тестовой выборки к каждому из классов и нахождение максимума из этих вероятностей. Тестовая выборка имеет размер 15% от все выборки.

Рисунок 7 – процесс обучения модели и получения предсказания для тестовой выборки
На рисунке 8 изображена плотность распределения списка max_abs_probs, в котором хранятся максимумы среди вероятностей для каждого класса для всех объектов тестовой выборки.

Рисунок 8 – плотность распределения списка max_abs_probs
2.7 Оценка качества модели с помощью кросс-валидации
 Оценка точности модели по одной тестовой выборке не является достаточно точной. Поэтому для более надёжной оценки должна использоваться одна из стратегий кросс-валидации. Так как исходный массив данных не упорядочен по времени (то есть не является временным рядом) и доли классов примерно равны, то можно использовать простую стратегию KFold. Её суть заключается в том, что выборка разбивается на k равных частей. На k-1 части осуществляется обучение модели, на оставшейся части проводится тестирование модели. Процесс реализуется таким способом, что каждая часть должна один раз быть в качестве тестовой. Результаты работы модели на тестовых выборках усредняются. Из-за того, что модели тестировались и обучались на разных выборках точность и устойчивость модели может быть определена более точно, чем при одном тестировании модели. 
3 Анализ полученных результатов
3.1 Анализ системы в разрезе точности критериев оценки результатов матча
	Первый критерий предсказывает количество голов, забитых командой, находящейся дома. Очевидно, что критерий может быть переопределён и для команды, находящейся в гостях. 
	На рисунке 9 показан процесс кросс-валидации и точность модели 
 
Рисунок 9 – проведение стратегии KFold для первого критерия
Предположение, сделанное в пункте 2.3, оправдалось. Модель не смогла найти сильных зависимостей между переменными и точно предсказывать результат матча (точность предсказания равняется 40%). Однако стоит отметить, что данная задача является задачей многоклассовой классификации с числом классов равным 5. Значит, точность модели в два раза превышает точность слепого угадывания класса, что является неплохим показателем для такой вариативной игры как футбол.
	Рассмотрим теперь более слабый второй критерий, который предсказывает, забьёт ли домашняя команда хотя бы один гол или нет. На рисунке 10 показан процесс кросс-валидации и точность модели для второго критерия.

Рисунок 10 – проведение стратегии KFold для второго критерия
	Классификатор смог предсказать 63% матчей. Этот критерий, как и говорилось в пункте 2.3, легче предсказать. Стоит отметить, что сложность модели для второго критерия существенно меньше, чем для первого. Это можно увидеть, например, по оптимальному количеству деревьев. Для первого критерия необходимо было 400 деревьев, а для второго всего 20.

 
3.2 Анализ системы в разрезе уверенности модели в своей классификации
	
	Важным моментом для поставленной задачи является степень уверенности классификатора в своей правоте. В качестве степени уверенности можно считать долю наибольшего класса в листе дерева, куда спустился классифицируемый объект. Рассмотрим распределение этой величины для тестовой выборки для каждого критерия и проанализируем зависимость точности и уверенности в предсказании. Хорошим сигналом будет вывод о том, что значения средней точности и средней уверенности по всей тестовой выборке достаточно похожи.


Рисунок 11 – распределение степени уверенности классификатора для первого критерия оценки результатов матча.

Рисунок 12 – распределение степени уверенности классификатора для второго критерия оценки результатов матча.

	Как видно из графиков, среднее значение точности очень близко к среднему значению уверенности модели в классификации. Это означает, что модель не переобучилась и степень уверенности модели адекватна входным данным. Другими словами, если модель не уверена в классификации, то это можно увидеть по примерно равным вероятностям, которые она даёт для каждого класса. И наоборот, если модель уверена в классификации, то будет существовать класс, у которого вероятность намного больше всех остальных. 









ЗАКЛЮЧЕНИЕ
В ходе работы была реализована система сбора данных о футбольных матчах в реальном времени и система анализа этих данных. Полученные результаты достаточно хорошо могут предсказывать результат всего матча по первым 15 минутам игры. Однако существует предположение, что обе системы можно существенно улучшить. Систему сбора данных можно реализовать с помощью методов распределённого программирования, чтобы повысить устойчивость работы. В системе анализа данных можно попытаться найти новые признаки из существующих и новые взаимосвязи между признаками с помощью многослойных искусственных нейронных сетей.



















СПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ
1 Документация по работе с библиотекой Celery. 2018 [Электронный ресурс]. – URL: http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html 
2 Статья «XGBoost: A Scalable Tree Boosting System». 2016 [Электронный ресурс]. – URL: https://arxiv.org/abs/1603.02754 
3 Статья «Introduction to Boosted Trees». 2015 [Электронный ресурс]. – URL: http://xgboost.readthedocs.io/en/latest/model.html
4 Дьяконов, A. Г. Анализ данных, обучение по прецедентам, логические игры, системы WEKA, RapidMiner и MatLab (практикум на ЭВМ кафедры математических методов прогнозирования). — МАКСПресс, 2010. — 278 с.
 5 Онлайн-курс «Обучение на размеченных данных». 2017 [Электронный ресурс]. – URL: https://www.coursera.org/learn/supervised-learning/home/welcome (дата обращения: 10.12.2017).
6 Видеолекции курса «Машинное обучение». 2016 [Электронный ресурс]. – URL: https://yandexdataschool.ru/edu-process/courses/machine-learning (дата обращения 27.04.2018).








ПРИЛОЖЕНИЕ 
Листинг программы:
Файл celeryconfig.py: 

broker_url = 'pyamqp://'
result_backend = 'rpc://'
task_serializer = 'json'
result_serializer = 'json'
accept_content = ['json']
enable_utc = True
beat_schedule = {
    'find-new-games-10-20': {
        'task': 'tasks.get_games_between_10_20_min',
        'schedule': 600.0,
    },
    'update_45': {
        'task': 'tasks.process_45_min_dict',
        'schedule': 300.0,
    },
    'update_90': {
        'task': 'tasks.process_90_min_dict',
        'schedule': 300.0,
    },
    'update_global': {
        'task': 'tasks.process_global_dict',
        'schedule': 600.0,
    }
}

Файл src.py:
import asyncio
import datetime

import requests
from bs4 import BeautifulSoup as bs
import time
import pandas as pd
from collections import defaultdict
import sqlite3

from time_consts import END_1_TIME_MIN, END_GAME_MIN

SOCCER_URL = "https://betsapi.com/ci/soccer"
BASE_URL = 'https://betsapi.com'
doubled_stats = ['Possession %', 'Off Target', 'On Target', 'Dangerous Attacks', 'Attacks']


def get_goals(game_url: str):
    html = get_html(game_url)
    soup = bs(html, 'lxml')
    game_goals = soup.find('span', class_='red-color').text.strip()
    return tuple(map(int, game_goals.split('-')))


def get_html(url):
    r = requests.get(url)
    return r.text


def get_html_football():
    return get_html(SOCCER_URL)


def get_games_10_20_list_links(html):
    soup = bs(html, 'lxml')
    games = soup.find_all('tr', class_='c_1')
    goals = [(BASE_URL + game.find('td', class_='text-center').find('a').get('href'),
              game.find('td', class_='text-center').find('a').get('href')) for game in games if
             10 <= int(game.find('span', class_='race-time').text.strip()[:2]) <= 20]
    return goals


def save_finally_stats(stats_dict: dict):
    goals1 = stats_dict['Goals'][0]
    goals2 = stats_dict['Goals'][1]
    corners1 = stats_dict['Corners'][0]
    corners2 = stats_dict['Corners'][1]
    ycard1 = stats_dict['Yellow Card'][0]
    ycard12 = stats_dict['Yellow Card'][1]
    rcard1 = stats_dict['Red Card'][0]
    rcard2 = stats_dict['Red Card'][1]
    penalt1 = stats_dict['Penalties'][0]
    penalt2 = stats_dict['Penalties'][1]
    subst1 = stats_dict['Substitutions'][0]
    subst2 = stats_dict['Substitutions'][1]
    attack1 = stats_dict['Attacks'][0]
    attack2 = stats_dict['Attacks'][1]
    dangatt1 = stats_dict['Dangerous Attacks'][0]
    dangatt2 = stats_dict['Dangerous Attacks'][1]
    ontarget1 = stats_dict['On Target'][0]
    ontarget2 = stats_dict['On Target'][1]
    offtarget1 = stats_dict['Off Target'][0]
    offtarget2 = stats_dict['Off Target'][1]
    possession = stats_dict['Possession %'][0]
    goals1_45 = stats_dict['goals_45'][0]
    goals2_45 = stats_dict['goals_45'][1]
    goals1_90 = stats_dict['goals_90'][0]
    goals2_90 = stats_dict['goals_90'][1]

    conn = sqlite3.connect('db')
    cur = conn.cursor()
    cur.execute('INSERT into stats values (?, ?, ?, ?, ?, ?, ?, ?,'
                ' ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)',
                (
                    goals1,
                    goals2,
                    corners1,
                    corners2,
                    ycard1,
                    ycard12,
                    rcard1,
                    rcard2,
                    penalt1,
                    penalt2,
                    subst1,
                    subst2,
                    attack1,
                    attack2,
                    dangatt1,
                    dangatt2,
                    ontarget1,
                    ontarget2,
                    offtarget1,
                    offtarget2,
                    possession,
                    goals1_45,
                    goals2_45,
                    goals1_90,
                    goals2_90
                ))
    conn.commit()
    cur.close()
    conn.close()


def parse_game(link: str):
    game_html = get_html(link)

    soup = bs(game_html, 'lxml')
    minute = int(soup.find('span', class_='race-time').text.strip()[:-1])
    print(minute)
    if minute:
        df_list = pd.read_html(game_html)   # read all tables
        df_stat = pd.DataFrame(df_list[0])  # first table is stats

        team1, stat, team2 = df_stat[[0]], df_stat[[1]], df_stat[[2]]  # 3 columns
        stats_dict = defaultdict(lambda: (0, 0))

        for i, (team1, stat, team2) in df_stat.iterrows():
            print(team1, stat, team2)
            stats_dict[str(stat)] = (str(team1), str(team2))
        # key in stats_dict is name of statistic
        for key in stats_dict:
            if key in doubled_stats:
                stats_dict[key] = (stats_dict[key][0].split()[0], stats_dict[key][1].split()[0])
        del stats_dict['nan']
        for key in stats_dict:
            stats_dict[key] = (int(stats_dict[key][0]), int(stats_dict[key][1]))
        return [datetime.datetime.now() + datetime.timedelta(END_1_TIME_MIN - minute),
                datetime.datetime.now() + datetime.timedelta(END_GAME_MIN - minute),
                stats_dict]


async def filter_links(links: list) -> list:
    filtered_links = []
    print('filter start: ' + str(datetime.datetime.now()))
    for link in links:
        game_html = get_html(link)
        soup = bs(game_html, 'lxml')
        minute = int(soup.find('span', class_='race-time').text.strip()[:2])
        if 10 <= minute <= 20:
            filtered_links.append(link)
        await asyncio.sleep(8)
    print('filter end: ' + str(datetime.datetime.now()))
    return filtered_links


def process_link_for_bot(link: str) -> bool:
    game_html = get_html(link)

    soup = bs(game_html, 'lxml')
    minute = int(soup.find('span', class_='race-time').text.strip()[:2])
    print(minute)
    if 10 < minute < 20:
        df_list = pd.read_html(game_html)
        df_stat = pd.DataFrame(df_list[0])

        team1, stat, team2 = df_stat[[0]], df_stat[[1]], df_stat[[2]]
        temp_dict = defaultdict(lambda: (0, 0))

        for i, (team1, stat, team2) in df_stat.iterrows():
            print(team1, stat, team2)
            temp_dict[str(stat)] = (str(team1), str(team2))
        for key in temp_dict:
            if key in doubled_stats:
                temp_dict[key] = (temp_dict[key][0].split()[0], temp_dict[key][1].split()[0])
        del temp_dict['nan']
        for key in temp_dict:
            temp_dict[key] = (int(temp_dict[key][0]), int(temp_dict[key][1]))

        goals1 = temp_dict['Goals'][0]
        goals2 = temp_dict['Goals'][1]
        corners1 = temp_dict['Corners'][0]
        corners2 = temp_dict['Corners'][1]
        ycard1 = temp_dict['Yellow Card'][0]
        ycard12 = temp_dict['Yellow Card'][1]
        rcard1 = temp_dict['Red Card'][0]
        rcard2 = temp_dict['Red Card'][1]
        penalt1 = temp_dict['Penalties'][0]
        penalt2 = temp_dict['Penalties'][1]
        subst1 = temp_dict['Substitutions'][0]
        subst2 = temp_dict['Substitutions'][1]
        attack1 = temp_dict['Attacks'][0]
        attack2 = temp_dict['Attacks'][1]
        dangatt1 = temp_dict['Dangerous Attacks'][0]
        dangatt2 = temp_dict['Dangerous Attacks'][1]
        ontarget1 = temp_dict['On Target'][0]
        ontarget2 = temp_dict['On Target'][1]
        offtarget1 = temp_dict['Off Target'][0]
        offtarget2 = temp_dict['Off Target'][1]
        possession = temp_dict['Possession %'][0]

        pos1_ = possession >= 60
        attack1_ = (attack1 - attack2) * 2
        dangatt1_ = (dangatt1 - dangatt2) * 4
        ontarget1_ = (ontarget1 - ontarget2) * 7
        offtarget1_ = (offtarget1 - offtarget2) * 5
        corners1_ = (corners1 - corners2) * 5
        res1 = attack1_ + dangatt1_ + ontarget1_ + offtarget1_ + corners1_
        if pos1_ and res1 > 80:
            return True

        pos2_ = possession <= 40
        attack2_ = (attack2 - attack1) * 2
        dangatt2_ = (dangatt2 - dangatt1) * 4
        ontarget2_ = (ontarget2 - ontarget1) * 7
        offtarget2_ = (offtarget2 - offtarget1) * 5
        corners2_ = (corners2 - corners1) * 5
        res2 = attack2_ + dangatt2_ + ontarget2_ + offtarget2_ + corners2_
        if pos2_ and res2 > 80:
            return True
        return False
    return False


def get_stats(links):
    for link in links:
        # game_html = get_html(link)
        # soup = bs(game_html, 'lxml')
        parse_game(link)
        time.sleep(1)


def main():
    html = get_html(SOCCER_URL)
    games_links = get_games_10_20_list_links(html)
    # test_link = [games_links[10]]
    print(games_links)
    get_stats(games_links)


if __name__ == '__main__':
    main()

файл tasks.py:
