Evaluation Warning: The document was created with Spire.Doc for Python.
МИНИСТЕРСТВО НАУКИ И ВЫСШЕГО ОБРАЗОВАНИЯ РОССИЙСКОЙ ФЕДЕРАЦИИ
Федеральное государственное бюджетное образовательное учреждение 
высшего образования
«КУБАНСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ»
(ФГБОУ ВО «КубГУ»)

Факультет компьютерных технологий и прикладной математики
Кафедра вычислительных технологий


КУРСОВАЯ РАБОТА

ИЗУЧЕНИЕ МЕТОДОВ КЛАССИФИКАЦИИ ДОКУМЕНТОВ ДЛЯ ОПРЕДЕЛЕНИЯ ЭМОЦИОНАЛЬНОЙ ОКРАСКИ ТЕКСТА

Работу выполнил______________________________________ И.В.Толстиков
(подпись)
Направление подготовки 02.03.02 — «Фундаментальная информатика и_____
                                                       (код, наименование)
информационные технологии,_курс__3________________________________ 

Направленность (профиль)   _______«Вычислительные технологии»________

Научный руководитель
канд.техн.наук., доц. ___________________________________Т.А.Приходько
(подпись, дата)
Нормоконтролер
канд.техн.наук., доц. __________________________________Е.Е.Полупанова
(подпись, дата)



Краснодар 
2021

РЕФЕРАТ

Курсовая работа 33 с., 29 рис., 9 источников.
Изучение методов классификации документов для определения эмоциональной окраски текста.
В работе изучены методы классификации текста. Рассмотрены их свойства, преимущества, ограничения, и выполнены сравнения полученных с помощью указанных методов классификаций.
Цель работы – изучение методов классификации документов для определения эмоциональной окраски текста, проведение анализа рассматриваемых данных и получение предсказаний, достаточно близких к реальным данным.
В работе рассмотрен и проанализирован ряд способов, связанных с классификацией.
Практическая часть работы представлена реализацией рассматриваемых методов и сравнением полученных с помощью этих методов предсказаний, составленных на данных для тестирования. Рассматриваемые методы реализованы на языке программирования Python.
СОДЕРЖАНИЕ

Введение	4
1 Подходы к сентиментному анализу	6
1.1 Формальная постановка задачи классификации	6
1.2 Формальная постановка задачи определения тональности текстов	7
1.3 Модели для построения векторного представления	8
1.3.1 «Мешок слов»	8
1.3.2 Word2Vec	9
1.4 Методы классификации тональности	11
1.4.1 Методы, основанные на правилах и словарях	11
1.4.2 Машинное обучение с учителем	12
1.5 Оценка эффективности классификатора	16
2 Программная реализация классификаторов	17
2.1 Инструменты анализа данных	17
2.2 Реализация классификаторов	18
2.2.1 TextBlob	18
2.2.2 Vader	18
2.2.3 Логическая регрессия	19
2.2.4 SVM (Метод опорных векторов)	20
2.2.5 FastText	20
2.3 Данные для реализации и проверки классификаторов.	21
3 Сравнение классификаторов	22
Заключение	33
Список использованных источников	34
Приложение	35


ВВЕДЕНИЕ

Сентиментным анализом (или анализом тональности текстов) принято называть область компьютерной лингвистики, призванную заниматься исследованием эмоций и мнений, содержащихся в текстах. Мнением (тональностью) называют суждение о какой-либо сущности или её аспекте, высказанное неким субъектом и окрашенное положительно, негативно, либо нейтрально. Умение распознавать тональность текстов широко применимо в различных задачах, таких как разработка систем рекомендаций, призванных помочь потребителю при выборе товаров или услуг на анализе его предпочтений, анализе новостных ресурсов на предмет тональности сообщений относительно различных персон или событий, поддержке поисковых систем и систем извлечения информации, психологических исследованиях и так далее.
Но большие возможности сопровождаются множеством проблем, с которыми сталкиваются исследователи при попытке определения тональности текста. Например, тональность может зависеть от предметной области текста: слово «огромный», применимое к описанию телевизора, имеет положительную тональность, но как характеристика телефона, это слово принимает уже негативный оттенок.
Так же сентиментный анализ плохо справляется с распознаванием саркастических высказываний. Такие выражения могут иметь общую тональность, обратную тональности отдельных слов: «здесь просто превосходное обслуживание, особенно мне понравился холодный стейк».
Целью курсовой работы является изучение подходов к сентиментному анализу выработка критериев оценки эмоциональной окраски текста.
Курсовая работа состоит из трех глав.
Первая глава содержит общие теоретические сведения о задаче сентиментного анализа.
Вторая глава описывает программную реализацию моделей сентиментного анализа.
В третьей главе происходит сравнение рассматриваемых моделей.
1 Подходы к сентиментному анализу

1.1 Формальная постановка задачи классификации

Пусть заданы некоторое конечное множество категорий  и конечное множество документов  и неизвестная целевая функция , которая для каждой пары  определяет, соответствуют ли они друг другу: .Задача состоит в том, чтобы найти максимально близкую к функции  функцию . Функция  называется классификатором [1].
Машинное обучение основывается на начальной коллекции документов . При этом значение целевой функции  известно для каждой пары . Документы из  разделяют на две непересекающиеся коллекции.
1)  «Учебную» . Коллекция документов, с помощью которой создается классификатор .  обучается индуктивно, основываясь на замеченных характеристиках этих документов.
2)  «Тестовую» . Коллекция документов, на которой тестируется эффективность построенного классификатора. Каждый «тестовый» документ подается на вход классификатору , затем сравнивается результат классификатора  с известным значением функции . Классификатор считается тем эффективнее, чем чаще эти значения совпадают.
Документ 𝑑 ∈ 𝑄 называется положительным или отрицательным примером для категории с, если значение функции Ф(𝑑, 𝑐). равно 1 или 0, соответственно.
Существует два различных наиболее распространённых вида классификации. В зависимости от ответа классификация бывает двух видов.
1)  Точная: . Таким образом, классификация является точной, когда каждой паре  ставится в соответствие булево значение: истина или ложь. То есть, соответствует ли документ категории или нет.
2)  Ранжированная: . Таким образом, классификация является ранжированной, когда каждой паре  ставится в соответствие число, характеризующее степень принадлежности документа к тому или иному классу и лежащее в диапазоне .

1.2 Формальная постановка задачи определения тональности текстов

Тональность текста определяется тремя факторами:
1)  Субъект тональности;
2)  Тональная оценка (например, позитив/нейтрально/негатив);
3)  Объект тональности.
Под субъектом тональности подразумевается автор, под объектом тональности – тот, о ком автор высказывает свое мнение, под тональной оценкой – эмоциональное отношение автора к такому объекту [2]. Формальная модель объекта: каждый объект  представляется в виде конечного набора атрибутов , который включает в себя и сам объект в виде специального атрибута.
Мнение – это четверка , где  – это некоторый объект,  – это атрибут объекта ,  – это тональность мнения по отношению к атрибуту ,  – это владелец мнения, а  – это время, в которое было высказано мнение.
Тональность  представлена определенной шкалой. Выделяют три типа шкал.
1)  Двухзначная шкала. Шкала тональности имеет только два значения: положительная тональность и отрицательная.
2)  Трехзначная шкала. К предыдущим двум вариантам добавляется третье значение нейтральное, которое может обозначать либо отсутствие тональности, либо одновременное наличие как положительной, так и отрицательной тональности.
3)  Многозначная шкала. Шкала тональности имеет более 3 значений. Существует множество вариантов таких шкал, отличающихся количеством значений тональности и наличием нейтрального значения.

1.3 Модели для построения векторного представления

	1.3.1 «Мешок слов»

«Мешок слов» (Bag-of-Words) – это модель, которая обучается на словаре, составленном из слов всех документов. 
Алгоритм построения модели [3].
1)  Составляется словарь из всех слов, встречающихся в тексте, предварительно исключаются все знаки препинания, числа и «стоп-слова».
2)  Для каждого документа определяется вектор, каждая компонента которого соответствует термину из словаря, а её значение определяется числом, равным количеству встреч слова в тексте. Размерность вектора соответствует мощности словаря.
Например, есть 2 документа.
1)  «Саша любит смотреть фильмы в кинотеатре. Маша любит смотреть фильмы дома».
2)  «Саша не любит смотреть дома футбольные матчи».

Словарь будет выглядеть следующим образом: {«Саша», «любит», «смотреть», «фильмы», «в», «кинотеатре», «Маша», «дома», «не», «футбольные», «матчи»}. Тогда векторное представление документов, согласно словарю, будет выглядеть следующим образом:
1)  ;
2)  .

1.3.2 Word2Vec

В данной модели для получения векторов используется машинное обучение. Изначально задается размерность векторов, которые заполняются случайными величинами, во время обучения значения компонент векторов буду меняться, причем вектор каждого слова будет максимально схож с векторами типичных соседей и максимально отличаться от векторов слов, которые соседями данному слову не являются. Компоненты векторов никак не связаны с конкретными словами из словаря. 
Алгоритм построения модели [4]:
1)  составляется словарь терминов, встретившихся во всех документах. Его размер практически не ограничивается, исключаются только слова, имеющие наименьшую встречаемость;
2)  каждому термину в словаре сопоставляется частота встречаемости во всех документах;
3)  для кодирования словаря строится дерево Хаффмана;
4)  производится субдискретизация частых слов;
5)  для этих слов применяется один из алгоритмов: CBOW (Continuous Bag-of-Words) или Skip-gram;
6)  применяется нейронная сеть прямого распространения с функцией активации иерархический softmax или негативное семплирование (negative sampling).
На рисунке 1 представлена архитектура CBOW.

Рисунок 1 – Архитектура CBOW

Она аналогична нейронной сети прямого распространения, где нелинейный скрытый слой удаляют, а проекция слоя является общей для всех слов, таким образом, все слова находятся в одинаковом положении. Очень похоже на модель «мешок слов» (Bag-of-Words): порядок слов никак не влияет на проекции. Задача архитектуры при обучении модели – предсказать слово по имеющемуся контексту. CBOW в отличие от BOW использует непрерывное распределенное представление контекста, поэтому и имеет такое название.
Архитектура Skip-gram, изображенная на рисунке 2, похожа на CBOW, но вместо того, чтобы предсказывать текущее слово исходя из окружения, она пытается для текущего слова предсказать контекст – слова, стоящие в пределах определенного диапазона (до и после данного слова). Увеличение контекстного окна улучшает качество получаемых векторов, но заметно увеличивает вычислительную сложность.


Рисунок 2 – Архитектура Skip-gram

1.4 Методы классификации тональности

1.4.1 Методы, основанные на правилах и словарях

Заранее имеется словарь размеченных данных, в котором каждому слову соответствует определенное настроение. При этом каждое слово в документе вносит свой определенный вклад в смысл и эмоциональную окраску текста, имеет свой вес [5]. Для назначения каждому слову веса существуют различные виды статистических мер. Например, , описываемая уравнением (1).


где
 – число вхождений слова  в документ , 
 – общее количество всех слов в документе, 
 – количество документов в корпусе, 
 – количество документов, в которых встречается слово .
	Мера  имеет следующий вид:



Из уравнения (2) следует, что тональность текста считается путём суммирования значения тональностей каждого отдельного слова.

1.4.2 Машинное обучение с учителем

Сутью таких методов является то, что на первом этапе обучается машинный классификатор на заранее размеченных текстах, а затем полученная модель используется при анализе новых документов.
Алгоритм построения модели [6]:
1)  собирается коллекция документов, на основе которой обучается машинный классификатор;
2)  каждый документ раскладывается в виде вектора признаков, по которым он будет исследоваться;
3)  указывается правильный тип тональности для каждого документа;
4)  производится выбор алгоритма классификации и метод для обучения классификатора;
5)  полученная модель используется для определения тональности документов новой коллекции.

1.4.2.1 Логическая регрессия

Логическая регрессия применяется для прогнозирования вероятности возникновения некоторого события по значениям множества признаков. Для этого вводится так называемая зависимая переменная , принимающая лишь одно из двух значений – как правило, это числа  (событие не произошло) и  (событие произошло), и множество независимых переменных (также называемых признаками, предикторами или регрессорами) – вещественных , на основе значение которых требуется вычислить вероятность принятия того или иного значения зависимой переменной [7].
Делается предположение о том, что вероятность наступления события  описывается уравнением (3).


где 
 
 и  – вектор-столбцы значений независимых переменных  и параметров (коэффициентов регрессии) – вещественных чисел  соответственно, 
 – логическая функция (иногда называемая сигмоидой или логит-функции), описываемая уравнением (4).



Логическая кривая (сигмоида) для уравнения (4) изображена на рисунке 3.

Рисунок 3 – График сигмоиды (4)

Так как  принимает лишь значения 0 и 1, вероятность принятия значения 0 описывается уравнением (5).



Для краткости функцию распределения  при заданном  можно записать в виде уравнения (6).



1.4.2.2 Метод опорных векторов

Основной идеей метода является перевод исходных векторов в пространство более высокой размерности и поиск разделяющей гиперплоскости в новом пространстве [8]. 
Обозначим множество документов за  , его элементы соответственно  . Будем рассматривать задачу бинарной классификации, поэтому, не уменьшая общности, обозначим  Множество 
Гиперплоскость задается уравнением (7).



Тогда документы одного класса должны удовлетворять условию , а другого – условию . Зафиксируем гиперплоскость, тогда параллельные гиперплоскости, содержащие опорные вектора, будут описываться уравнением (8).



Отклонение  одно и тоже в силу того, что расстояние до опорных векторов будет одинаковым, иначе такая гиперплоскость точно не будет оптимальной.
Сделаем нормировку, а именно поделим вектор  и число  на . Тогда параллельные гиперплоскости описываются уравнением (9).



Для двумерного случая это продемонстрировано на рисунке 4.


Рисунок 4 – Опорные вектора и параллельные гиперплоскости

Чтобы найти оптимальную гиперплоскость, нужно решить задачу оптимизации, описываемую формулой (10).



1.5 Оценка эффективности классификатора

Поскольку будет проводиться сравнение различных классификаторов, необходимо ввести метрики, по которым будет вестись сравнение. Каждый отзыв обучающей выборки принадлежит одному из классов. Натренированный классификатор расставляет метки на тестовом множестве. По итогам тестовая выборка разбивается на 4 группы:
1)  True Positive (TP) – истинно положительные;
2)  True Negative (TN) – истинно отрицательные;
3)  False Positive (FP) – ложно положительные;
4)  False Negative (FN) – ложно отрицательные.
Их размеры характеризуют работу классификатора на данной выборке. Для оценки вводятся показатели точность (precision), описываемая уравнением (7), и полнота (recall), описываемая уравнением (8).





Для оценки классификатора требуется только одно число, характеризующее его работу. В качестве такой метрики можно взять F-меру, которая позволяет найти баланс между точностью и полнотой [9]. Представляет собой их среднее гармоническое взвешенное и описывается уравнением (9).



Значение F лежит в промежутке и зависит от значения , при значении коэффициента  предпочтение отдается полноте, а при  – точности.

2 Программная реализация классификаторов

2.1 Инструменты анализа данных

Одним из наиболее популярных языков программирования для анализа данных является Python. Для него создано большое количество библиотек и фреймворков. В работе используется среда разработки PyCharm. Для визуализации в работе используются библиотеки matplotlib и sklearn, хранение данных осуществляется в оперативной памяти с помощью библиотеки pandas. Pandas – программная библиотека на языке Python для обработки и анализа данных. Работа pandas с данными строится поверх библиотеки NumPy, являющейся инструментом более низкого уровня. 

2.2 Реализация классификаторов

2.2.1 TextBlob

TextBlob – это метод, основанный на применении тональных словарей. Реализован в модуле classifiers.py в виде класса TextBlobSentiment с необходимыми методами. Пример реализации метода TextBlob изображен на рисунке 5.


Рисунок 5 – Пример реализации метода TextBlob

2.2.2 Vader

VADER (Valence Aware Dictionary sEntiment Reasoner) – это инструмент анализа настроений на основе правил. Реализован в модуле classifiers.py в виде класса VaderSentiment с необходимыми методами. Пример реализации VADER изображен на рисунке 6.


Рисунок 6 – Пример реализации метода VADER

2.2.3 Логическая регрессия

Метод реализован в модуле classifiers.py в виде класса LogisticRegressionSentiment c необходимыми методами. Пример реализации логической регрессии изображен на рисунке 7.


Рисунок 7 – Пример реализации метода логической регрессии
2.2.4 SVM (Метод опорных векторов)

Метод реализован в модуле classifiers.py в виде класса SVMSentiment с необходимыми методами. Пример реализации SVM изображен на рисунке 8.


Рисунок 8 – Пример реализации метода SVM

2.2.5 FastText

FastText – это NLP-библиотека от Facebook Research, содержащая предобученные готовые векторные представления слов, а также классификатор. Обучение классификатора осуществляется в модуле train_fasttext.py. Пример реализации обучения классификатора изображен на рисунке 9. 


Рисунок 9 – Пример реализации обучения метода FastText

Классификатор реализован в модуле classifiers.py в виде класса FastTextSentiment с необходимыми методами. Пример реализации классификатора изображен на рисунке 10.


Рисунок 10 – Пример реализации метода FastText

2.3 Данные для реализации и проверки классификаторов.

В качестве начальных и проверочных данных используется набор SST, состоящий из 11855 предложений, извлеченных из обзоров фильмов с детальными надписями настроения от 1 до 5:
1)  1 – крайне отрицательный;
2)  2 – слабо отрицательный;
3)  3 – нейтральный;
4)  4 – слабо положительный;
5)  5 – крайне положительный.
А также из 215 154 фраз, составляющих каждое предложение в наборе данных. Пример данных изображен на рисунке 11.


Рисунок 11 – Фрагмент набора данных для классификации

3 Сравнение классификаторов

Тестирование и обучение классификаторов проводилось на одних и тех же данных.
Для визуализации результатов классификатора использовалась матрица ошибок. Матрица ошибок сводит в таблицу процент верных предсказаний для каждого класса, поэтому становится легче увидеть, какие классы наименее точно предсказаны для данного классификатора. В идеале классификатор должен получить почти 100% правильных предсказаний, поэтому все элементы вне побочной диагонали должны быть как можно ближе к нулю, как на рисунке 12.


Рисунок 12 – Пример матрицы ошибок
 
Начнем анализ с самого простого классификатора из рассматриваемых: классификатор на основе метода TextBlob. Классификатор показывает следующие результаты предсказания, изображенные с помощью матрицы ошибок на рисунке 13.


Рисунок 13 – Матрица ошибок предсказания TextBlob

На рисунке 14 покажем точность и F-меру полученных предсказаний.


Рисунок 14 – Оценка TextBlob

Метод, работающий на правилах и словарях, показал плохую точность, а также F-меру, что говорит о том, что классификатор не мог точно определять, к какому из 5 классов принадлежит рассматриваемое предложение. Из матрицы ошибок видно, что классификатор с трудом отделяет нейтральный класс от всех остальных. Это связано с тем, что классификатор на основе TextBlob пытается дать результат, основанный на прямом результате анализа грамматики: он не пытается проверить, является ли все предложение отрицательным или нет, а определяет тональность отдельных слов и после усредняет значение для определения тональности всего предложения. И в результате усреднения большинство предложений получили нейтральную окраску.
Рассмотрим классификатор, построенный на основе VADER, который так же работает на правилах. Классификатор показывает предсказания, изображенные на рисунке 15.


Рисунок 15 – Матрица ошибок предсказания VADER
На рисунке 16 покажем точность и F-меру классификатора.


Рисунок 16 – Оценка VADER

Классификатор на основе VADER так же, как и предыдущий классификатор, усредняет тональности всех слов в предложение, но VADER был разработан с акцентом на тексты в социальных сетях. Это означает, что в нем много внимания уделяется правилам, которые отражают суть текста, обычно встречаемого в социальных сетях: короткие предложения со смайликами, повторяющиеся слова и обильное использование знаков препинания. Этим и объясняется большой разброс вне побочной диагонали: очень низкие или очень высокие составные оценки присваиваются тексту, который имеет много капитализации, пунктуации, повторения слов и смайликов. Тем не менее классификатор на основе VADER показывает лучшие результаты, чем классификатор на основе TextBlob, что можно увидеть на рисунке 17.


Рисунок 17 – Сравнение предсказаний классификаторов

Недостатком методов, основанных на словарях и правилах, является большая затратность на составление этих самых словарей и правил, а также неспособность правильно обрабатывать незнакомые конструкции и слова, а в условиях постоянно развивающегося языка это большой минус.
От подходов, основанных на правилах и словарях, перейдем к машинному обучению с учителем. Рассмотрим классификатор на основе логической регрессии. Классификатор показывает предсказания, изображенные на рисунке 18.


Рисунок 18 – Матрица ошибок логической регрессии

На рисунке 19 покажем точность и F-меру классификатора.


Рисунок 19 – Оценка логической регрессии

Сравним результаты классификатора на основе логической регрессии с результатами предыдущих классификаторов на рисунке 20.


Рисунок 20 – Сравнение предсказаний классификаторов

Как видим, машинное обучение с учителем показывает себя гораздо лучше методов на словарях и правилах, однако в случае с логической регрессией результаты буду значительно лучше, если данные будут линейно разделяемы, а в случае с 5 классами добиться этого крайне сложно. Протестируем классификаторы на двухзначной шкале тональности, а именно отнесем предложения к отрицательному и положительному классам. На рисунке 21 покажем матрицу ошибок для классификатора на основе TextBlob.


Рисунок 21 – Матрица ошибок TextBlob
На рисунке 22 покажем матрицу ошибок для классификатора на основе VADER.


Рисунок 22 – Матрица ошибок VADER

На рисунке 23 покажем матрицу ошибок для классификатора на основе логичстиеской регрессии. 


Рисунок 23 – Матрица ошибок логистической регрессии

И сравним результаты классификаторов на рисунке 24.


Рисунок 24 – Сравнение предсказаний классификаторов

Логическая регрессия смогла отнести к правильным классам 80 процентов входных предложений, что является крайне хорошим результатом в задаче определения тональности текста и по этому показателю она превосходит классификаторы на основе TextBlob и VADER. 
Если же мы посмотрим на другой рассматриваемый метод машинного обучения с учителем – метод опорных векторов, то на рисунке 25 увидим превосходство логической регрессии в точности в задаче бинарной классификации.


Рисунок 25 – Сравнение предсказаний классификаторов
Но также на рисунке 26 увидим улучшение этого показателя у метода опорных векторов перед логической регрессией в задаче отнесения к 5 классам. Действительно SVM поддерживает как линейные, так и нелинейные решения, к тому же он лучше справляется с выбросами. 


Рисунок 26 – Сравнение предсказаний классификаторов

На рисунке 27 отобразим матрицу ошибок для SVM.


Рисунок 27 – Матрица ошибок SVM
Процент правильно определенных нейтральных предложений все ещё низок, но в сравнении с предыдущими классификаторами SVM точнее относит предложения к крайне отрицательным и крайне положительным классам.
У классификатора, основанного на методе FastText, есть ряд преимуществ в сравнении с предыдущими рассматриваемыми. Иерархический метод классификации, обладающий большой информационной ёмкостью. Для модели векторных представлений слов используется skip-gram с негативным сэмплированием, таким образом для обучения векторной модели создаются отрицательные примеры, то есть показываются пары слов, которые не являются соседями по контексту. Но главным преимуществом выступает добавление к основной модели subword-модели – представления слова через цепочки символов (n-граммы) с n от 3 до 6 символов от начала до конца слова плюс само слово целиком. 
Такой подход позволяет работать с теми словами, которые модель раннее не встречала. Совокупность этих преимуществ выливается в самую большую точность для задачи отнесения предложения к одному из пяти классов из рассматриваемых классификаторов, изображенную на рисунке 28.


Рисунок 28 – Сравнение предсказаний классификаторов

На матрице ошибок, изображенной на рисунке 29, видно, что классификатор гораздо точнее определяет предложения, имеющие нейтральную окраску, что и дает более высокую точность.

Рисунок 29 – Матрица ошибок FastText

ЗАКЛЮЧЕНИЕ

В результате проведенного анализа методов определения тональности текста были выделены методы, дающие лучшие результаты. Методы были протестированы на большом массиве данных из общедоступных источников.
Исследование позволило сделать следующие выводы.
Подходы на правилах и словарях могут быть наиболее точными из всех рассматриваемых, однако это требует очень больших затрат в условиях развивающихся языков, что является преимуществом методов машинного обучения с учителем, которые автоматически находят необходимые признаки. Недостатком методов машинного обучения можно выделить требования большого количества данных для обучения, которые должны быть сбалансированы для точной классификации в задачах с количеством классов больших двух. Лучший результат из рассматриваемых классификаторов получил классификатор FastText, основанный на машинном обучении и использующий одновременно модели векторного представления слов skip-gram и CBOW.
В результате исследования сделан вывод о том, что классификация тональности на более чем два класса – это очень сложная задача. Даже с тремя классами очень сложно достичь хорошей точности независимо от применяемого подхода. По этой причине в большинстве случаев классификаторы настроение используются для бинарной классификации (только положительные или отрицательные настроения).
СПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ

1 Николенко С., Кадурин А., Архангельская Е. Глубокое обучение. – СПб.: Питер, 2018. – 480 с.
2 Baccianella S. Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining, 2010. – P. 2200-2204. 
3 Ma S., Sun X., Wang Y., Lin J.  Bag-of-Words as Target for Neural Machine Translation [Электронный ресурс]. – URL: https://arxiv.org/pdf/1805.04871.pdf (дата обращения: 22.04.2020).
4 Rong X.  word2vec Parameter Learning Explained [Электронный ресурс]. – URL: https://arxiv.org/pdf/1411.2738.pdf (дата обращения: 22.04.2020).
5 Пазельская А., Соловьев А. Метод определения эмоций в текстах на русском языке. – М.: Ай-Теко, 2011. – С. 510-522.
6 Клековкина М.В., Котельников Е.В. Метод автоматической классификации текстов по тональности, основанный на словаре эмоциональной лексики. – М.: Ай-Теко, 2012. – 6 с.
7 Джеймс Г., Уиттон	Д., Хасти Т., Тибширани Р. Введение в статическое обучение с примерами на языке R/ пер. с англ. Мастицкий С. Э. – М.: ДМК Пресс, 2017. – 456 с.
8 Кун М., Джонсон	К. Предиктивное моделирование на практике/ пер. с англ. «Питер». – СПб.: Питер, 2019. – 640 с.
9 Миронов А.М. Машинное обучение [Электронный ресурс]. – URL: http://intsys.msu.ru/staff/mironov/machine_learning_vol1.pdf (дата обращения 02.10.2020).

ПРИЛОЖЕНИЕ  
Код программы

train_fasttext.py

import argparse
import os
import fasttext


def trainer(filepath: str,
            train_file: str,
            valid_file: str,
            model_path: str,
            hyper_params: dict) -> None:

    train = os.path.join(filepath, train_file)
    valid = os.path.join(filepath, valid_file)
    model = fasttext.train_supervised(
        input=train,
        autotuneValidationFile=valid,
        **hyper_params,
    )
    os.makedirs(model_path, exist_ok=True)
    model.save_model(f"{model_path}.ftz")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--filepath', type=str, help="Dataset path", default="../data/sst")
    parser.add_argument('--train', type=str, help="Training set filename", default="3sst_train.txt")
    parser.add_argument('--valid', type=str, help="Validation set filename", default="3sst_dev.txt")
    parser.add_argument('--model', type=str, help="Trained model path", default="../models/fasttext/model")
    parser.add_argument("--duration", type=int, default=1800, help="Autotuning duration in seconds")
    parser.add_argument("--modelsize", type=str, default="10M", help="Max allowed size for autotuned model file (`5M` means 5 MB)")
    parser.add_argument("--disable_verbose", action="store_true", help="Disable verbosity in autotuning output")

    args = parser.parse_args()

    hyper_params = {
        "autotuneDuration": args.duration,
        "autotuneModelSize": args.modelsize,
        "verbose": 2 if args.disable_verbose else 3,  # '3' means verbose
    }

    trainer(args.filepath, args.train, args.valid, args.model, hyper_params)

tree2tabular.py

import pytreebank
import sys
import os

out_path = os.path.join(sys.path[0], '2sst_{}.txt')
dataset = pytreebank.load_sst('./raw_data')

for category in ['train', 'test', 'dev']:
    with open(out_path.format(category), 'w', encoding='utf-8') as outfile:
        for item in dataset[category]:
            if item.to_labeled_lines()[0][0] == 3:
                param = 2
                outfile.write("__label__{}\t{}\n".format(
                    param,
                    item.to_labeled_lines()[0][1]
                ))
            elif item.to_labeled_lines()[0][0] == 1:
                param = 1
                outfile.write("__label__{}\t{}\n".format(
                    param,
                    item.to_labeled_lines()[0][1]
                ))
            # elif item.to_labeled_lines()[0][0] == 2:
            #     param = 2
            #     outfile.write("__label__{}\t{}\n".format(
            #         param,
            #         item.to_labeled_lines()[0][1]
            #     ))
            elif item.to_labeled_lines()[0][0] ==0:
                param = 1
                outfile.write("__label__{}\t{}\n".format(
                    param,
                    item.to_labeled_lines()[0][1]
                ))
            elif item.to_labeled_lines()[0][0] == 4:
                param = 2
                outfile.write("__label__{}\t{}\n".format(
                    param,
                    item.to_labeled_lines()[0][1]
                ))

print(len(dataset['train']))

classifier.py

import pandas as pd
from sklearn.metrics import f1_score, accuracy_score


class Base:
    def __init__(self) -> None:
        pass

    def read_data(self, fname: str, lower_case: bool=False,
                  colnames=['truth', 'text']) -> pd.DataFrame:
        df = pd.read_csv(fname, sep='\t', header=None, names=colnames)
        df['truth'] = df['truth'].str.replace('__label__', '')
        # Categorical data type for truth labels
        df['truth'] = df['truth'].astype(int).astype('category')
        # Optional lowercase for test data (if model was trained on lowercased text)
        if lower_case:
            df['text'] = df['text'].str.lower()
        return df

    def accuracy(self, df: pd.DataFrame) -> None:
        acc = accuracy_score(df['truth'], df['pred'])*100
        f1 = f1_score(df['truth'], df['pred'], average='macro')*100
