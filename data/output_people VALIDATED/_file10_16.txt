317
ПРИМЕНЕНИЕ МЕТОДОВ ИНТЕЛЛЕКТУАЛЬНОГО АНАЛИЗА ДАННЫХ ДЛЯ ЗАДАЧ МЕДИЦИНСКОЙ ДИАГНОСТИКИ
4 Анализ полученных результатов 
----------
В результате применения алгоритмов классификации к выборке медицинских данных была получена следующая информация о средней точности классификаторов:
Таблица1. Средняя точность классификаторов.
Наиболее успешным алгоритмом оказался метод k ближайших соседей со средней точностью 78,4%. Этот высокий показатель можно объяснить сходством логики работы алгоритма и логики принятия решения врачом. Практическим плюсом этого алгоритма является возможность его доработки таким образом, чтобы он выводил список ближайших соседей. Это поможет специалисту вспомнить похожие случаи из его практики и сильно сузить область возможных решений.
Решающее дерево тоже показало неплохой результат. Его практическое преимущество заключается в том, что его можно доработать так, чтобы оно могло выводить вопросы в узлах дерева [2]. А врач, проанализировав эти вопросы мог улучшить свои методики постановки диагнозов. Особое внимание при этом надо обращать на те вопросы, которые идут первыми, так как именно они чаще всего позволяют наиболее сильно сократить дальнейший поиск. Это объясняется тем, что критериями выбора того или иного условия в узле дерева чаще всего становятся индекс Джини или кросс-энтропийный критерий [2] [3].
Рисунок 5 – сравнение точности на обучающей и тестовой выборках для различных значений максимальной глубины дерева в алгоритме решающего дерева.
На рисунке 5 видно, что уже при максимальной глубине 7 дерево начинает переобучаться и подгоняться под обучающую выборку, а точность на тестовой выборке уменьшается.
Рисунок 6 – сравнение точности на обучающей и тестовой выборках наивного байесовского классификатора.
На рисунке 6 видно, что байесовский классификатор работает хорошо: он не переобучился и точность его предсказания достаточно высока. Следует вспомнить, что в результате первичного визуального анализа была обнаружена пара признаков BMI и SkinThick, которые не являются независимыми. Также вполне возможно, что существуют зависимости не только между двумя признаками, а между тремя и более признаками. Однако, это не помешало данному алгоритму показать достойные результаты.
Метод линейной классификации SVM показал самый низкий результат. Это означает, что данные оптимально не разделяются (n-1)-мерной гиперплоскостью. Однако алгоритм SVM потенциально может дать хороший результат, если нелинейно преобразовать исходные данные или использовать нелинейные ядра [1] [2] [5].