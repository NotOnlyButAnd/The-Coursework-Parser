233
ПРИМЕНЕНИЕ МЕТОДОВ ИНТЕЛЛЕКТУАЛЬНОГО АНАЛИЗА ДЛЯ ПРЕДСКАЗАНИЯ РЕЗУЛЬТАТОВ СПОРТИВНЫХ СОРЕВНОВАНИЙ
2 Система анализа данных 
2.6 Подбор гиперпараметров и обучение модели 
----------
Гиперпараметры – настройки алгоритма, решающего задачу. В случае с градиентным бустингом на решающих деревьях гиперпараметрами являются:
* максимальная глубина одного дерева;
* коэффициент регуляризации;
* количество деревьев в модели;
* шаг обучения (learning rate);
* минимальный порог разбиения выборки;
* целевая функция и другие.
Наиболее простой способ подбора гиперпараметров – перебор по заданной сетке. Этот подход называется GridSearch. Достоинства метода в том, что если задать плотную сетку, то можно получить хорошую модель на выходе. Очевидным минусом является большой объём вычислений. Существует много вариаций поиска по сетке без полного перебора. Можно, например, использовать подход случайного выбора параметров сетки или  стохастического градиентного спуска[6]. Однако стоит отметить, что для цели курсовой работы подойдёт и обычный поиск по сетке, так как выборка не очень большая и, следовательно, вычислительных ресурсов для обучения модели хватает даже у ноутбука.
На рисунке 5 показан процесс задания сетки перебора параметров,  поиска оптимальных параметров с помощью инструмента GridSearchCV и результат этого поиска.
Рисунок 5 – поиск оптимальных значений гиперпараметров
На рисунке 6 показано обучение модели, нахождение вероятностей принадлежности для всех объектов из тестовой выборки к каждому из классов и нахождение максимума из этих вероятностей. Тестовая выборка имеет размер 15% от все выборки.
Рисунок 7 – процесс обучения модели и получения предсказания для тестовой выборки
На рисунке 8 изображена плотность распределения списка max_abs_probs, в котором хранятся максимумы среди вероятностей для каждого класса для всех объектов тестовой выборки.
Рисунок 8 – плотность распределения списка max_abs_probs